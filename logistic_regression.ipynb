{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Logistic regression class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 0.1,\n",
    "        n_iter: int = 10,\n",
    "    ) -> None:\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{__class__.__name__} class: n_iter = {self.n_iter}, learning_rate = {self.learning_rate}\"\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False) -> None:\n",
    "        # Reset index for X dataset\n",
    "        X = deepcopy(X)\n",
    "        X.reset_index(drop=True)\n",
    "\n",
    "        # Fill the first column of feature matrix with \"1\" values (for intercept)\n",
    "        X.insert(loc=0, column=\"intercept\", value=1)\n",
    "\n",
    "        num_observations, num_features = X.shape\n",
    "\n",
    "        # Set initial weights equal to 1\n",
    "        weights = [1] * num_features\n",
    "\n",
    "        # Make iterations to update weights\n",
    "        for i in range(1, self.n_iter + 1):\n",
    "            # Calculate predictions\n",
    "            y_predicted_logit = X.dot(weights)\n",
    "            y_predicted_probability = 1 / (1 + math.e ** (-y_predicted_logit))\n",
    "\n",
    "            eps = 1e-15\n",
    "            LogLoss = (-1 / num_observations) * sum(\n",
    "                y * np.log(y_predicted_probability + eps)\n",
    "                + (1 - y) * np.log(1 - y_predicted_probability + eps)\n",
    "            )\n",
    "\n",
    "            # Log after verbose iterations\n",
    "            if verbose and i % verbose == 0:\n",
    "                print(f\"{i} | loss: {LogLoss}\")\n",
    "\n",
    "            # Calculate gradient and new weights\n",
    "            gradient = (1 / num_observations) * ((y_predicted_probability - y).dot(X))\n",
    "            weights -= self.learning_rate * gradient\n",
    "\n",
    "        # Final (best) weights\n",
    "        self.weights = weights\n",
    "\n",
    "    def get_coef(self) -> np.array:\n",
    "        return np.array(self.weights[1:])\n",
    "    \n",
    "    def predict_proba(self, X) -> np.array:\n",
    "        X = deepcopy(X)\n",
    "\n",
    "        # Fill the first column of feature matrix with \"1\" values (for intercept)\n",
    "        X.insert(loc=0, column=\"intercept\", value=1)\n",
    "\n",
    "        y_predicted_logit = X.dot(self.weights)\n",
    "        y_predicted_probability = 1 / (1 + math.e ** (-y_predicted_logit))\n",
    "\n",
    "        return np.array(y_predicted_probability)\n",
    "    \n",
    "    def predict(self, X) -> np.array:\n",
    "        X = deepcopy(X)\n",
    "\n",
    "        # Fill the first column of feature matrix with \"1\" values (for intercept)\n",
    "    \n",
    "        y_predicted_probability = self.predict_proba(X)\n",
    "        y_predicted_class = np.where(y_predicted_probability > 0.5, 1, 0)\n",
    "\n",
    "        return np.array(y_predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd51c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ficticious dataset\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=14, n_informative=10, random_state=42\n",
    ")\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f\"col_{col}\" for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4c1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class instance\n",
    "\n",
    "sample_one = LogisticRegression(n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afc3cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 | loss: 1.8729518266222953\n",
      "20 | loss: 1.1626945313705068\n",
      "30 | loss: 0.8288847284427477\n",
      "40 | loss: 0.654884590222696\n",
      "50 | loss: 0.5606818660628201\n"
     ]
    }
   ],
   "source": [
    "sample_one.fit(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eb3d7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05247374,  0.63579113,  0.35707211,  0.20338172, -0.71400341,\n",
       "        0.65306157, -0.30353191,  0.74286901,  0.14726892,  0.16403292,\n",
       "        0.81238906,  0.0167088 ,  0.67663333,  1.21843872])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_one.get_coef()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
